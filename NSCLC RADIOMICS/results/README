# 📊 NSCLC Classification Results

This directory contains the **evaluation results** of the machine learning pipeline developed for the project:

> 🩺 *"Development of ML model for non-small cell lung cancer detection"*  
> MSc Thesis – Bioinformatics & Neuroinformatics, Ionian University

---

## 🧠 Experiment Setup

- **Dataset:** Radiomic features extracted from manually segmented lung nodules (N ≈ 471)
- **Classes:**  
  - Benign  
  - Adenocarcinoma  
  - Squamous cell carcinoma  
  - Large cell carcinoma  
- **Cross-validation:** Stratified 4-fold CV  
- **Hyperparameter tuning:** GridSearchCV  
- **Metrics:** F1-score (weighted), Accuracy, Precision, Recall

---

## 📈 Results Summary

| Feature Selection | Classifier | F1-score | Accuracy | Precision | Recall |
|-------------------|------------|----------|----------|-----------|--------|
| **CorrSF**        | Random Forest            | 0.5813 | 0.6815 | 0.5951 | 0.6815 |
| CorrSF            | Logistic Regression (L1) | 0.5001 | 0.4566 | 0.6152 | 0.4566 |
| CorrSF            | SVM (RBF)                | 0.5554 | 0.5499 | 0.5643 | 0.5499 |
| **Boruta**        | Random Forest            | 0.5796 | 0.6560 | 0.5563 | 0.6560 |
| Boruta           | Logistic Regression (L1) | 0.4027 | 0.3441 | 0.5907 | 0.3441 |
| Boruta           | SVM (RBF)                | 0.4721 | 0.4310 | 0.5573 | 0.4310 |
| **RFE-SVM**       | Random Forest            | 0.5794 | 0.6858 | 0.5838 | 0.6858 |
| RFE-SVM          | Logistic Regression (L1) | 0.5633 | 0.5309 | 0.6285 | 0.5309 |
| RFE-SVM          | SVM (RBF)                | 0.5761 | 0.5710 | 0.5826 | 0.5710 |
| **L1-LASSO**      | Random Forest            | 0.5801 | 0.6794 | 0.5915 | 0.6794 |
| L1-LASSO         | Logistic Regression (L1) | 0.5644 | 0.5372 | 0.6196 | 0.5372 |
| L1-LASSO         | SVM (RBF)                | **0.5950** | **0.6008** | 0.5908 | **0.6008** |
| **RF-imp**        | Random Forest            | 0.5795 | 0.6773 | 0.5541 | 0.6773 |
| RF-imp          | Logistic Regression (L1) | 0.4909 | 0.4522 | 0.5726 | 0.4522 |
| RF-imp          | SVM (RBF)                | 0.5610 | 0.5520 | 0.5766 | 0.5520 |

📁 Detailed results table: [`ml_results.csv`](./ml_results.csv)

---

## 📊 Visualization

The following figure shows the weighted **F1-score** across all feature selection methods and classifiers:

![F1-score comparison](./ml_results.png)

- **X-axis:** Feature Selection Method  
- **Y-axis:** F1-score  
- **Color:** Classifier

---

## 🧪 Key Insights

🔍 **Top-performing combination:**  
- `L1-LASSO + SVM (RBF)` achieved the best performance with:
  - **F1-score:** 0.5950  
  - **Accuracy:** 0.6008  

📊 **Additional observations:**

- **Random Forest** models achieved consistent accuracy across different feature selection methods (~0.67–0.68).  
- **RFE-SVM + RF** achieved the highest accuracy (0.6858), indicating the effectiveness of recursive feature elimination.  
- **Logistic Regression (L1)** consistently showed lower accuracy but higher **precision**, making it a potential choice for tasks where false positives are critical.  
- **Boruta** did not outperform simpler filters (CorrSF), suggesting that domain-specific feature relevance is crucial.

---

## 📍 Next Steps

- 🔬 Validate the model on external public datasets (e.g., TCIA NSCLC Radiomics).  
- 🧠 Implement **SHAP** and **LIME** for feature attribution and explainability.  
- 🩺 Integrate histopathological features to enhance classification accuracy.  
- 🚀 Package the pipeline into a deployable API or web service for clinical use.

---

## 📁 Files in this Directory

| File | Description |
|------|------------|
| `ml_results.csv` | Full results table (all metrics, all experiments) |
| `ml_results.png` | Barplot visualization (F1-score vs FS method & classifier) |
| `selected_features_*.csv` | Top features selected by each feature selection method |

---

📄 *This report is part of the MSc thesis project by **Evita Marini** – Ionian University MSc Program in Bioinformatics and Neuroinformatics.*
